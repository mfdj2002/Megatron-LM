GPUS_PER_NODE=$GPUS_PER_NODE -e WORLD_SIZE=$WORLD_SIZE -e MASTER_ADDR=$MASTER_ADDR -e MASTER_PORT=$MASTER_PORT -e NNODES=$NNODES -e NODE_RANK=$NODE_RANK \


example:
DISTRIBUTED_ARGS="
    --nproc_per_node $GPUS_PER_NODE \
    --nnodes $NNODES \
    --node_rank $NODE_RANK \
    --master_addr $MASTER_ADDR \
    --master_port $MASTER_PORT
"

FIXED_ARGS

--recompute-activations,
--distribute-saved-activations,
--recompute-method=uniform, #choices=['uniform', 'block'], or use block and specify --recompute-num-layers
--use-flash-attn 
--use-mcore-models 
--use-distributed-optimizer
--overlap-grad-reduce
--no-delay-grad-reduce
--overlap-param-gather
--use-cpu-initialization


SEARCH_ARGS=

--sequence-parallel

--recompute-granularity=full, #['full', 'selective']

--no-clone-scatter-output-in-embedding, action='store_false',
                       help='If not set, clone the output of the scatter in embedding layer to GC original tensor.',
                       dest='clone_scatter_output_in_embedding'


--tensor-model-parallel-size # type=int, default=1,
                       help='Degree of tensor model parallelism.')

--pipeline-model-parallel-size # type=int, default=1,
                       help='Degree of pipeline model parallelism.')

--num-layers-per-virtual-pipeline-stage # type=int, default=None,
                       help='Number of layers per virtual pipeline stage'
    

--empty-unused-memory-level #default=0, type=int,
                       choices=[0, 1, 2],
                       help='Call torch.cuda.empty_cache() each iteration '
                       '(training and eval), to reduce fragmentation.'
                       '0=off, 1=moderate, 2=aggressive.')

--context-parallel-size # type=int, default=1,elp='Degree of context parallelism.')



PROFILING_ARGS=

'--profile', action='store_true',
                       help='Enable nsys profiling. When using this option, nsys '
                       'options should be specified in commandline. An example '
                       'nsys commandline is `nsys profile -s none -t nvtx,cuda '
                       '-o <path/to/output_file> --force-overwrite true '
                       '--capture-range=cudaProfilerApi '
                       '--capture-range-end=stop`.' 


group.add_argument('--profile-step-start', type=int, default=10,
                       help='Global step to start profiling.')
    group.add_argument('--profile-step-end', type=int, default=12,
                       help='Global step to stop profiling.')
    group.add_argument('--profile-ranks', nargs='+', type=int, default=[0],
                       help='Global ranks to profile.')




ADVANCED_ARGS=
    --tp-comm-overlap # action='store_true', help = 'Enables the '
                        ' overlap of Tensor parallel communication and GEMM kernels.')
    --tp-comm-overlap-cfg # type=str, default=None, 
                        help = 'Config file when tp_comm_overlap is enabled.')

    group.add_argument('--manual-gc', action='store_true',
                       help='Disable the threshold-based default garbage '
                       'collector and trigger the garbage collection manually. '
                       'Manual garbage collection helps to align the timing of '
                       'the collection across ranks which mitigates the impact '
                       'of CPU-associated jitters. When the manual gc is enabled, '
                       'garbage collection is performed only at the start and the '
                       'end of the validation routine by default.')
    group.add_argument('--manual-gc-interval', type=int, default=0,
                       help='Training step interval to trigger manual garbage '
                       'collection. When the value is set to 0, garbage '
                       'collection is not triggered between training steps.')
    group.add_argument('--no-manual-gc-eval', action='store_false',
                       help='When using manual garbage collection, disable '
                       'garbage collection at the start and the end of each '
                       'evaluation run.', dest='manual_gc_eval')

    group.add_argument('--use-ring-exchange-p2p', action='store_true',
                       default=False, help='If set, use custom-built ring exchange '
                       'for p2p communications. Note that this option will require '
                       'a custom built image that support ring-exchange p2p.')
